{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oSto_2RfCggX"
      },
      "outputs": [],
      "source": [
        "#1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multithreading vs. Multiprocessing largely comes down to the type of tasks you are handling, and how the underlying system handles them. Here's a breakdown of when each is preferable:\n",
        "\n",
        "#1. Multithreading (Shared Memory, Lightweight)\n",
        "#Multithreading involves using multiple threads within the same process, sharing the same memory space. It is typically more efficient for I/O-bound tasks or tasks that involve waiting (e.g., file handling, network requests) because switching between threads incurs less overhead than creating separate processes.\n",
        "\n",
        "#When to Prefer Multithreading:\n",
        "#I/O-bound tasks: If your program spends most of its time waiting on I/O (e.g., reading from files, sending/receiving network requests), multithreading is ideal. The Global Interpreter Lock (GIL) is not a problem in these cases because the threads are often in a waiting state.\n",
        "\n",
        "#Examples:\n",
        "#Web scraping\n",
        "#File operations\n",
        "#Network communication (e.g., web servers)\n",
        "#Lightweight operations: If you need to handle many small, quick tasks, multithreading will have lower overhead than spawning multiple processes.\n",
        "\n",
        "#Example: Handling multiple client connections in a lightweight server.\n",
        "#GUI applications: In applications with graphical user interfaces, where responsiveness is important, multithreading allows the main application thread to stay responsive while other threads handle background tasks.\n",
        "\n",
        "#Resource-sharing is easy: Threads share memory space, so communication between threads (e.g., sharing variables, data structures) is much simpler than in multiprocessing where inter-process communication (IPC) is required.\n",
        "\n",
        "#Limitations of Multithreading:\n",
        "#Global Interpreter Lock (GIL): In CPython (the most common Python interpreter), the GIL ensures that only one thread executes Python bytecode at a time, making it unsuitable for CPU-bound tasks.\n",
        "#Potential for race conditions: Threads can access shared data concurrently, leading to bugs like race conditions or deadlocks if not properly synchronized.\n",
        "#2. Multiprocessing (Separate Memory, Heavyweight)\n",
        "#Multiprocessing involves creating separate processes, each with its own memory space. This is generally better for CPU-bound tasks where you need to maximize CPU usage by running computations in parallel.\n",
        "\n",
        "#When to Prefer Multiprocessing:\n",
        "#CPU-bound tasks: If your program is doing a lot of computation (e.g., mathematical calculations, data processing), multiprocessing is preferable because each process runs in its own memory space and can fully utilize multiple CPU cores. The GIL doesn't affect multiprocessing since each process has its own GIL.\n",
        "\n",
        "#Examples:\n",
        "#Machine learning model training\n",
        "#Image or video processing\n",
        "#Scientific simulations\n",
        "#Tasks that are independent: If the tasks you are running don't need to share state or resources frequently, multiprocessing is ideal because processes are isolated and won't interfere with each other.\n",
        "\n",
        "#Example: Parallel processing of independent data batches.\n",
        "#Memory-intensive tasks: If your tasks require large amounts of memory or complex data structures, multiprocessing can isolate them in separate processes, preventing memory conflicts.\n",
        "\n",
        "#Bypassing GIL limitations: Since each process has its own GIL, multiprocessing allows you to fully leverage multiple cores in Python.\n",
        "\n",
        "#Limitations of Multiprocessing:\n",
        "#Higher overhead: Creating processes is more expensive than creating threads because each process has its own memory space. This is less of an issue on multi-core machines but can be a problem for very lightweight tasks.\n",
        "#Inter-process communication (IPC): Communication between processes is more complex and slower than between threads, as processes don’t share memory and must use IPC mechanisms (e.g., pipes, queues).\n",
        "#Memory duplication: Each process has its own memory space, so data must be duplicated in each process. This can lead to higher memory usage compared to multithreading.\n",
        "#Summary:\n",
        "#Use multithreading when:\n",
        "\n",
        "#You are dealing with I/O-bound tasks (networking, file handling).\n",
        "#You need lightweight parallelism and efficient memory sharing.\n",
        "#You want to avoid high overhead from process creation and memory duplication.\n",
        "#Use multiprocessing when:\n",
        "\n",
        "#You have CPU-bound tasks that need to run on multiple cores.\n",
        "#Your tasks are independent and can run in isolation.\n",
        "#You want to bypass Python’s GIL for parallel computing.\n",
        "#By analyzing the task requirements, resource constraints, and whether your application is more I/O-bound or CPU-bound, you can decide which approach fits best."
      ],
      "metadata": {
        "id": "7kTaKxoXCuM-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "0GiXjDo_D0fc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A process pool is a high-level abstraction in concurrent programming that helps manage and control a pool of worker processes to perform tasks in parallel. It simplifies the process of running multiple tasks concurrently without having to manually manage the creation, synchronization, or termination of processes.\n",
        "\n",
        "#Key Concepts:\n",
        "#Worker processes: The pool consists of several worker processes that are pre-initialized and kept alive to handle tasks.\n",
        "#Task submission: Tasks (functions or operations) are submitted to the pool, which assigns them to available worker processes.\n",
        "#Reusability: After a worker completes a task, it is recycled and can be assigned another task without the need to create a new process.\n",
        "#Load balancing: The pool handles load balancing, ensuring that no single worker is overloaded while others remain idle.\n",
        "#How a Process Pool Works:\n",
        "#Initialization: A process pool is initialized with a fixed number of worker processes (e.g., Pool(4) creates 4 worker processes).\n",
        "#Task submission: The user submits tasks (functions or operations) to the pool using methods like apply(), apply_async(), map(), or map_async().\n",
        "#Task assignment: The pool distributes tasks among the worker processes, running them in parallel. If all workers are busy, new tasks are queued until a worker becomes available.\n",
        "#Task execution: Each worker runs its assigned task and returns the result.\n",
        "#Result collection: The pool collects results and makes them available to the main program when the tasks are completed.\n",
        "#Shutdown: Once all tasks are finished or no more tasks are being submitted, the pool can be closed and the worker processes terminated.\n",
        "#Advantages of Using a Process Pool:\n",
        "#Efficient Process Management:\n",
        "\n",
        "#Without a process pool, you would need to manually create and terminate a new process for each task, which incurs significant overhead, especially for small or short-lived tasks.\n",
        "#The process pool manages these operations for you by pre-spawning a fixed number of worker processes, avoiding the repeated creation and destruction of processes.\n",
        "#Parallel Execution:\n",
        "\n",
        "#Tasks are run in parallel, utilizing multiple CPU cores, which is beneficial for CPU-bound tasks that can take advantage of multiprocessing.\n",
        "#A process pool allows you to distribute the workload across multiple processors, speeding up execution.\n",
        "#Reusability:\n",
        "\n",
        "#Workers in the pool are reused for different tasks, reducing the overhead of process creation and teardown. This is especially important when dealing with many small tasks.\n",
        "#Load Balancing:\n",
        "\n",
        "#The pool ensures that tasks are distributed across the available worker processes efficiently. If one worker is busy with a long-running task, others can continue processing new tasks, ensuring that system resources are used optimally.\n",
        "#Concurrency Simplification:\n",
        "\n",
        "#The process pool abstracts away many of the complexities of multiprocessing. You don’t need to manually handle process synchronization, communication, or managing queues for task assignment. The pool takes care of these details.\n",
        "#Result Handling:\n",
        "\n",
        "#The pool provides mechanisms to collect the results of tasks once they complete. For example, using map() will return the results of all tasks in the order they were submitted, even if they were executed in parallel.\n",
        "#Common Methods in Process Pools:\n",
        "#apply(func, args): Submits a task to the pool and waits for it to complete (synchronous).\n",
        "#apply_async(func, args): Submits a task to the pool but returns immediately, allowing the main thread to continue (asynchronous).\n",
        "#map(func, iterable): Similar to Python’s map(), but executes in parallel using the pool's worker processes. It applies the function to each item in the iterable and returns the results.\n",
        "#map_async(func, iterable): Asynchronous version of map(), which allows the main thread to continue executing while the tasks are being processed.\n",
        "#close(): Prevents new tasks from being submitted to the pool but allows all ongoing tasks to complete.\n",
        "#join(): Waits for all worker processes to complete their tasks after close() has been called.\n",
        "#Example Usage in Python (Using multiprocessing.Pool):\n",
        "#code\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a pool with 4 worker processes\n",
        "    with Pool(4) as pool:\n",
        "        # Map the function 'square' to a list of inputs\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "        print(results)  # Output: [1, 4, 9, 16, 25]\n",
        "#In this example:\n",
        "\n",
        "#A process pool with 4 workers is created.\n",
        "#The map() function distributes the task of squaring numbers in the list across the workers.\n",
        "#The pool manages the distribution, execution, and result collection in parallel, providing an efficient way to handle multiple tasks.\n",
        "#When to Use a Process Pool:\n",
        "#CPU-bound tasks: It’s ideal for tasks that need to utilize multiple CPU cores, such as mathematical computations, data processing, or image/video manipulation.\n",
        "#Task parallelism: When you have a large number of independent tasks that can be executed concurrently.\n",
        "#Task reusability: When you have many small tasks to process and don’t want the overhead of creating and tearing down processes for each task.\n",
        "#In summary, a process pool provides a convenient and efficient way to manage multiple processes, maximizing CPU utilization while minimizing overhead and complexity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZZjZcBNEMxj",
        "outputId": "b61afc6c-9b50-4f68-e5a1-6455537f9229"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "Wsp6_3IEEgAc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiprocessing is a programming technique that involves executing multiple processes concurrently, allowing a program to perform several tasks at the same time by leveraging multiple CPU cores. In Python, it is especially useful for parallelizing CPU-bound tasks to improve performance.\n",
        "\n",
        "#What is Multiprocessing?\n",
        "#In computing, multiprocessing refers to running multiple independent processes, where each process runs in its own memory space and can be executed in parallel on different CPU cores. Each process can execute a task independently and communicate with other processes through mechanisms like pipes or queues.\n",
        "\n",
        "#In Python, the multiprocessing module provides tools for spawning processes, which can run concurrently to maximize CPU utilization and improve the efficiency of computational tasks.\n",
        "\n",
        "#Why Use Multiprocessing in Python?\n",
        "#Bypass the Global Interpreter Lock (GIL):\n",
        "\n",
        "#Python’s Global Interpreter Lock (GIL) is a mechanism that allows only one thread to execute Python bytecode at a time in a single process. This means that even if you use multiple threads in a Python program, they cannot run in true parallelism (on multiple CPU cores) when it comes to CPU-bound tasks.\n",
        "#Multiprocessing solves this problem by creating multiple independent processes, each with its own GIL. Since each process runs in its own memory space and can execute on different CPU cores, true parallelism is achieved.\n",
        "#Parallelize CPU-bound tasks:\n",
        "\n",
        "#Multiprocessing is especially useful for CPU-bound tasks, which are tasks that require significant CPU computation (e.g., large-scale mathematical calculations, image processing, scientific simulations, etc.).\n",
        "#By splitting the work across multiple processes, the workload can be distributed among different CPU cores, significantly speeding up the program.\n",
        "#Utilizing Multiple Cores:\n",
        "\n",
        "#Modern processors have multiple cores, but Python’s default execution model (with the GIL) does not utilize all the cores effectively for CPU-bound tasks. Multiprocessing allows you to take full advantage of multi-core processors by distributing tasks across different cores.\n",
        "#Each process can be assigned to a different core, maximizing performance for computational tasks.\n",
        "#Task Independence:\n",
        "\n",
        "#Since processes in multiprocessing run independently and do not share memory, each process operates in isolation. This reduces the risk of issues like race conditions and deadlocks, which are common in multi-threaded programs.\n",
        "#Each process has its own memory space, so memory management is more predictable and can handle large tasks that might cause memory issues in a single-threaded program.\n",
        "#How Multiprocessing Works in Python:\n",
        "#The multiprocessing module in Python enables the creation of new processes by forking the current process. Each process has its own memory space and runs independently of others. Here's how multiprocessing typically works:\n",
        "\n",
        "#Creating a Process:\n",
        "\n",
        "#You can create a new process using the Process class from the multiprocessing module. Each process runs a target function that executes the desired task.\n",
        "#code\n",
        "from multiprocessing import Process\n",
        "\n",
        "def task():\n",
        "    print(\"Task is running\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a new process\n",
        "    p = Process(target=task)\n",
        "    # Start the process\n",
        "    p.start()\n",
        "    # Wait for the process to finish\n",
        "    p.join()\n",
        "#Spawning Multiple Processes:\n",
        "\n",
        "#For parallel execution, you can spawn multiple processes and distribute tasks among them. Each process works on an independent part of the task, and the results can be combined later.\n",
        "#Inter-process Communication (IPC):\n",
        "\n",
        "#Since processes do not share memory, inter-process communication (IPC) is required to exchange data between processes. This is done using pipes, queues, or shared memory in Python.\n",
        "\n",
        "#Queues are commonly used for safe and easy communication between processes:\n",
        "\n",
        "#code\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def task(queue):\n",
        "    queue.put(\"Task is done\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    queue = Queue()\n",
        "    p = Process(target=task, args=(queue,))\n",
        "    p.start()\n",
        "    p.join()\n",
        "    print(queue.get())  # Output: Task is done\n",
        "#Process Pool:\n",
        "\n",
        "#Python’s multiprocessing.Pool allows for creating a pool of worker processes to efficiently handle a set of tasks. The pool takes care of distributing the tasks to available processes and managing results.\n",
        "#code\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(4) as pool:\n",
        "        results = pool.map(square, [1, 2, 3, 4])\n",
        "        print(results)  # Output: [1, 4, 9, 16]\n",
        "#When to Use Multiprocessing in Python:\n",
        "#CPU-bound tasks:\n",
        "\n",
        "#Multiprocessing is ideal when the task is CPU-intensive and benefits from parallel execution. Tasks that involve heavy computation, such as data processing, matrix operations, machine learning model training, and simulations, will see significant performance gains.\n",
        "#Avoiding GIL limitations:\n",
        "\n",
        "#If the program is suffering from Python’s GIL due to CPU-bound operations (where threads won’t help), switching to multiprocessing will allow multiple processes to run in parallel without GIL restrictions.\n",
        "#Independent task execution:\n",
        "\n",
        "#When you have tasks that can be performed independently without needing to share complex data structures between processes. Multiprocessing works best when tasks do not frequently need to communicate or share state.\n",
        "#Limitations of Multiprocessing:\n",
        "#High memory usage:\n",
        "\n",
        "#Each process has its own memory space, which means that memory is not shared between processes. This can lead to higher memory usage if large data structures need to be duplicated across processes.\n",
        "#Overhead:\n",
        "\n",
        "#There is some overhead involved in creating and managing processes, which might not make multiprocessing suitable for tasks that are very lightweight or quick.\n",
        "#Complexity of inter-process communication:\n",
        "\n",
        "#Sharing data between processes is more complicated compared to multithreading, as processes do not share memory. IPC mechanisms like queues and pipes are needed to communicate between processes.\n",
        "#Platform limitations:\n",
        "\n",
        "#On some platforms, particularly Windows, multiprocessing uses process spawning (instead of forking like in Unix-based systems), which can lead to performance penalties and more complexity when using certain types of tasks.\n",
        "#Conclusion:\n",
        "#Multiprocessing in Python is a powerful tool to achieve parallelism and improve the performance of CPU-bound tasks by utilizing multiple CPU cores. It is used to overcome the limitations imposed by the GIL, making it ideal for tasks that require heavy computation or independent execution. Although it comes with some overhead and complexity, multiprocessing can significantly speed up programs when used correctly."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaHRJQeBEkka",
        "outputId": "81af1e74-a013-45d6-fa88-4b3e3550caf0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task is running\n",
            "Task is done\n",
            "[1, 4, 9, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "#thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
      ],
      "metadata": {
        "id": "DihXbm-nFhkO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To avoid race conditions in a multithreading scenario where one thread adds numbers to a list and another removes them, we can use a threading.Lock to ensure that only one thread can access the list at a time.\n",
        "\n",
        "#Here's an example Python program demonstrating this with threading.Lock:\n",
        "\n",
        "#code\n",
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list between threads\n",
        "shared_list = []\n",
        "\n",
        "# Lock object to avoid race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_to_list():\n",
        "    for i in range(5):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulating some work\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            num = random.randint(1, 100)\n",
        "            shared_list.append(num)\n",
        "            print(f\"Added {num} to the list. Current list: {shared_list}\")\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_from_list():\n",
        "    for i in range(5):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulating some work\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            if shared_list:  # Check if the list is not empty\n",
        "                removed_num = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_num} from the list. Current list: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "# Create the two threads\n",
        "thread1 = threading.Thread(target=add_to_list)\n",
        "thread2 = threading.Thread(target=remove_from_list)\n",
        "\n",
        "# Start the threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)\n",
        "#Explanation:\n",
        "#Shared Resource (shared_list): A list is shared between two threads. One thread adds numbers, while the other removes numbers.\n",
        "#Lock (list_lock): A threading.Lock is used to ensure that only one thread can modify the list at a time, avoiding race conditions.\n",
        "#The with list_lock: block ensures that any operation on the shared list is thread-safe, as it locks the list before modifying it.\n",
        "#Thread Functions:\n",
        "#add_to_list(): Adds random numbers to the list.\n",
        "#remove_from_list(): Removes numbers from the list if it is not empty.\n",
        "#Thread Management:\n",
        "#Two threads are created: one for adding and one for removing numbers.\n",
        "#start() initiates the threads, and join() ensures that the main program waits for both threads to finish before printing the final list.\n",
        "#Output Example:\n",
        "#plaintext\n",
        "#code\n",
        "#Added 83 to the list. Current list: [83]\n",
        "#Removed 83 from the list. Current list: []\n",
        "#Added 25 to the list. Current list: [25]\n",
        "#Removed 25 from the list. Current list: []\n",
        "#Added 47 to the list. Current list: [47]\n",
        "#Removed 47 from the list. Current list: []\n",
        "#Added 96 to the list. Current list: [96]\n",
        "#Added 34 to the list. Current list: [96, 34]\n",
        "#Removed 96 from the list. Current list: [34]\n",
        "#Removed 34 from the list. Current list: []\n",
        "#Final list: []\n",
        "#The lock ensures that the shared list is accessed safely without race conditions, even when multiple threads are running concurrently."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IJ0TtjBFpZ0",
        "outputId": "4025e592-aff9-4fb8-ba55-7a9acd120339"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List is empty, nothing to remove.\n",
            "List is empty, nothing to remove.\n",
            "Added 73 to the list. Current list: [73]\n",
            "Removed 73 from the list. Current list: []\n",
            "List is empty, nothing to remove.\n",
            "Added 26 to the list. Current list: [26]\n",
            "Added 35 to the list. Current list: [26, 35]\n",
            "Removed 26 from the list. Current list: [35]\n",
            "Added 80 to the list. Current list: [35, 80]\n",
            "Added 49 to the list. Current list: [35, 80, 49]\n",
            "Final list: [35, 80, 49]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
      ],
      "metadata": {
        "id": "vznW9EFNGQJl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Python provides several methods and tools for safely sharing data between threads and processes, while avoiding issues like race conditions, deadlocks, or inconsistencies. These mechanisms are necessary because both threads and processes may concurrently access shared resources, leading to potential conflicts.\n",
        "\n",
        "#Sharing Data Between Threads\n",
        "#In Python, threads run in the same memory space, which means they can directly share variables and data structures. However, this can lead to race conditions if multiple threads try to read or write shared data simultaneously. To handle these issues, Python provides synchronization mechanisms in the threading module.\n",
        "\n",
        "#1. threading.Lock\n",
        "#A lock ensures that only one thread can access a shared resource at a time. When a thread acquires the lock, other threads trying to acquire it will be blocked until the lock is released. This prevents race conditions but may introduce deadlocks if not managed properly.\n",
        "#code\n",
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "def critical_section():\n",
        "    with lock:  # Automatically acquires and releases the lock\n",
        "        # Modify shared resource safely\n",
        "        pass\n",
        "#2. threading.RLock (Reentrant Lock)\n",
        "#A reentrant lock (RLock) is similar to a normal lock but allows a thread to acquire the lock multiple times without blocking itself. This is useful when the same thread needs to lock the same resource recursively.\n",
        "#code\n",
        "lock = threading.RLock()\n",
        "#3. threading.Condition\n",
        "#A condition variable allows one or more threads to wait until they are notified by another thread that some condition has been met. It is typically used in conjunction with a lock, allowing for complex thread synchronization (e.g., producer-consumer problems).\n",
        "#code\n",
        "condition = threading.Condition()\n",
        "\n",
        "def producer():\n",
        "    with condition:\n",
        "        # Modify shared data and notify waiting threads\n",
        "        condition.notify()\n",
        "\n",
        "def consumer():\n",
        "    with condition:\n",
        "        condition.wait()  # Wait for the condition to be met\n",
        "        # Access shared data\n",
        "#4. threading.Semaphore\n",
        "#A semaphore is a counter-based synchronization primitive that allows a certain number of threads to access a shared resource simultaneously. For example, if you initialize a semaphore with a count of 3, only three threads can access the resource at the same time.\n",
        "#code\n",
        "semaphore = threading.Semaphore(3)\n",
        "#5. threading.Event\n",
        "#An event is a flag that can be set or cleared by threads to signal that some condition has occurred. Other threads can wait for the event to be set before proceeding.\n",
        "#code\n",
        "event = threading.Event()\n",
        "\n",
        "def worker():\n",
        "    event.wait()  # Wait until event is set\n",
        "    # Perform task\n",
        "\n",
        "def controller():\n",
        "    # Perform some actions\n",
        "    event.set()  # Notify workers to proceed\n",
        "#6. threading.Queue\n",
        "#A queue is a thread-safe way to share data between threads. It allows threads to safely exchange data without using explicit locks. The queue.Queue class is synchronized and provides built-in thread-safe methods like put() and get().\n",
        "#code\n",
        "import queue\n",
        "q = queue.Queue()\n",
        "\n",
        "def producer():\n",
        "    q.put(10)  # Add data to the queue\n",
        "\n",
        "def consumer():\n",
        "    data = q.get()  # Get data from the queue\n",
        "#Sharing Data Between Processes\n",
        "#Processes, unlike threads, do not share memory. Each process has its own memory space, and data must be explicitly passed between them using inter-process communication (IPC) mechanisms. Python’s multiprocessing module provides tools to facilitate this communication.\n",
        "\n",
        "#1. multiprocessing.Queue\n",
        "#A queue in the multiprocessing module allows data to be safely exchanged between processes. It is a first-in, first-out (FIFO) structure, where one process can add data using put(), and another can retrieve it using get().\n",
        "#code\n",
        "from multiprocessing import Queue\n",
        "\n",
        "q = Queue()\n",
        "\n",
        "def producer(q):\n",
        "    q.put(\"Hello from process\")\n",
        "\n",
        "def consumer(q):\n",
        "    print(q.get())  # Output: Hello from process\n",
        "#2. multiprocessing.Pipe\n",
        "#A pipe provides a bidirectional communication channel between two processes. It allows the processes to send data back and forth directly. Pipes are typically used when you need simple, two-way communication.\n",
        "#code\n",
        "from multiprocessing import Pipe\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "\n",
        "def sender(conn):\n",
        "    conn.send(\"Data from child\")\n",
        "\n",
        "def receiver(conn):\n",
        "    print(conn.recv())  # Output: Data from child\n",
        "#3. multiprocessing.Value\n",
        "#A Value object allows multiple processes to share a single value in memory. It supports synchronization and ensures that only one process modifies the value at a time. Value works for basic data types like integers, floats, etc.\n",
        "#code\n",
        "from multiprocessing import Value\n",
        "\n",
        "shared_value = Value('i', 0)  # Integer shared between processes\n",
        "\n",
        "def increment(shared_value):\n",
        "    with shared_value.get_lock():  # Ensure safe access\n",
        "        shared_value.value += 1\n",
        "#4. multiprocessing.Array\n",
        "#Similar to Value, an Array object allows sharing of an array of data between processes. The array elements are protected by a lock, ensuring that only one process can modify the array at a time.\n",
        "#code\n",
        "from multiprocessing import Array\n",
        "\n",
        "shared_array = Array('i', [0, 1, 2])  # Array of integers shared between processes\n",
        "#5. multiprocessing.Manager\n",
        "#A manager provides shared objects like lists, dictionaries, and namespaces that can be safely accessed and modified by multiple processes. This is more flexible than Value and Array, as it can be used to share complex objects like lists, dictionaries, etc.\n",
        "#python\n",
        "#code\n",
        "from multiprocessing import Manager\n",
        "\n",
        "manager = Manager()\n",
        "shared_list = manager.list()  # Shared list\n",
        "shared_dict = manager.dict()  # Shared dictionary\n",
        "\n",
        "def modify_shared_data(shared_list, shared_dict):\n",
        "    shared_list.append(1)\n",
        "    shared_dict['key'] = 'value'\n",
        "#6. multiprocessing.Lock\n",
        "#A lock in the multiprocessing module works similarly to a threading lock but is used to protect shared resources between processes. Only one process can acquire the lock at a time, preventing concurrent access to shared resources.\n",
        "#python\n",
        "#code\n",
        "from multiprocessing import Lock\n",
        "\n",
        "lock = Lock()\n",
        "\n",
        "def task(lock):\n",
        "    with lock:\n",
        "        # Safe access to shared resource\n",
        "        pass\n",
        "#Summary of Tools:\n",
        "#Tool\tUse Case\tThreads or Processes\tDescription\n",
        "#threading.Lock\tAvoid race conditions\tThreads\tEnsures only one thread can access a resource at a time.\n",
        "#threading.RLock\tRecursive locking\tThreads\tAllows the same thread to acquire the lock multiple times.\n",
        "#threading.Condition\tComplex thread synchronization\tThreads\tEnables one thread to wait until notified by another thread.\n",
        "#threading.Semaphore\tControl access to a limited resource\tThreads\tLimits the number of threads that can access a resource simultaneously.\n",
        "#threading.Event\tSignaling between threads\tThreads\tUsed for thread coordination via setting and waiting for events.\n",
        "#threading.Queue\tSafe data sharing between threads\tThreads\tThread-safe FIFO queue for exchanging data between threads.\n",
        "#multiprocessing.Queue\tSafe data sharing between processes\tProcesses\tProcess-safe queue for exchanging data between processes.\n",
        "#multiprocessing.Pipe\tTwo-way communication between processes\tProcesses\tDirect communication between two processes via pipes.\n",
        "#multiprocessing.Value\tShare a single value between processes\tProcesses\tAllows safe access to a single shared value (e.g., int, float) between processes.\n",
        "#multiprocessing.Array\tShare an array between processes\tProcesses\tAllows safe access to a shared array between processes.\n",
        "#multiprocessing.Manager\tShare complex objects (lists, dicts)\tProcesses\tProvides shared lists, dicts, and other objects for processes.\n",
        "#multiprocessing.Lock\tAvoid race conditions\tProcesses\tEnsures only one process can access a resource at a time.\n",
        "#Each tool serves a specific purpose, and the choice depends on whether you're dealing with threads (shared memory space) or processes (separate memory spaces with IPC).\n"
      ],
      "metadata": {
        "id": "Ya5R1y9oGflw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so."
      ],
      "metadata": {
        "id": "kHn8PLFmIMal"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling exceptions in concurrent programs is crucial for several reasons. Concurrent programs involve multiple threads or processes running simultaneously, and if exceptions are not properly managed, they can lead to subtle, hard-to-debug issues like crashes, resource leaks, deadlocks, or inconsistent data states. In multi-threaded or multi-process applications, exceptions can occur in one thread or process and may not automatically propagate to others, making it vital to detect and handle them correctly.\n",
        "\n",
        "#Why Handling Exceptions in Concurrent Programs Is Crucial\n",
        "#Prevent Program Crashes:\n",
        "\n",
        "#Unhandled exceptions in concurrent tasks can cause entire programs to crash, especially in multi-threaded environments where one thread’s failure may lead to unpredictable behavior in other threads.\n",
        "#Resource Leaks:\n",
        "\n",
        "#Resources like file handles, network connections, and memory may not be released if exceptions occur without proper handling, especially when using shared resources. This can lead to resource exhaustion over time.\n",
        "#Deadlocks and Inconsistent States:\n",
        "\n",
        "#In concurrent programs, if a lock is acquired and an exception occurs before it is released, other threads may be blocked indefinitely, leading to deadlocks.\n",
        "#Shared data can be left in inconsistent states if exceptions interrupt operations partway through.\n",
        "#Improve Program Robustness:\n",
        "\n",
        "#Handling exceptions allows the program to gracefully recover from errors, providing fallback mechanisms or retry logic instead of crashing.\n",
        "#Debugging Concurrent Programs Is Challenging:\n",
        "\n",
        "#Debugging concurrency issues is much harder because of the non-deterministic nature of thread/process scheduling. Without exception handling, identifying the cause of a failure can be difficult since errors may not always propagate to the main thread or the parent process.\n",
        "#Techniques for Handling Exceptions in Concurrent Programs\n",
        "#Python provides several techniques and tools for handling exceptions in both multi-threaded and multi-process applications. These include methods for catching, logging, and propagating exceptions between threads or processes.\n",
        "\n",
        "#1. Handling Exceptions in Multithreading\n",
        "#In a multi-threaded program, exceptions in a thread typically do not propagate to the main thread. Therefore, you must explicitly handle exceptions within each thread.\n",
        "\n",
        "#a. Using try-except Blocks\n",
        "#The simplest way to handle exceptions in individual threads is to wrap the thread’s logic in a try-except block. This ensures that exceptions in the thread do not cause the entire program to fail silently.\n",
        "#python\n",
        "#code\n",
        "import threading\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        # Code that might raise an exception\n",
        "        raise ValueError(\"An error occurred in the thread\")\n",
        "    except Exception as e:\n",
        "        print(f\"Exception caught in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=task)\n",
        "thread.start()\n",
        "thread.join()\n",
        "#b. Propagating Exceptions to the Main Thread\n",
        "#To propagate exceptions from a thread back to the main thread, you can use a custom thread class to catch and re-raise exceptions.\n",
        "#code\n",
        "import threading\n",
        "\n",
        "class ExceptionThread(threading.Thread):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self._exception = None\n",
        "\n",
        "    def run(self):\n",
        "        try:\n",
        "            super().run()\n",
        "        except Exception as e:\n",
        "            self._exception = e\n",
        "\n",
        "    def join(self, *args, **kwargs):\n",
        "        super().join(*args, **kwargs)\n",
        "        if self._exception:\n",
        "            raise self._exception  # Re-raise the exception in the main thread\n",
        "\n",
        "def task():\n",
        "    raise ValueError(\"Error in thread\")\n",
        "\n",
        "thread = ExceptionThread(target=task)\n",
        "thread.start()\n",
        "\n",
        "try:\n",
        "    thread.join()\n",
        "except Exception as e:\n",
        "    print(f\"Exception caught in main thread: {e}\")\n",
        "#c. Using a Thread Pool (concurrent.futures.ThreadPoolExecutor)\n",
        "#The ThreadPoolExecutor from the concurrent.futures module makes handling exceptions easier by providing mechanisms to retrieve and handle exceptions raised by worker threads.\n",
        "#You can use the result() method to retrieve the return value of a thread and handle exceptions that occurred in the thread.\n",
        "#code\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def task():\n",
        "    raise ValueError(\"An error occurred in the thread\")\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(task)\n",
        "    try:\n",
        "        future.result()  # This will raise the exception if it occurred in the thread\n",
        "    except Exception as e:\n",
        "        print(f\"Exception caught: {e}\")\n",
        "#2. Handling Exceptions in Multiprocessing\n",
        "#In a multi-process environment, exceptions in one process do not affect other processes and are not automatically propagated to the parent process. You need to handle exceptions explicitly in each child process or use the available IPC mechanisms to pass exceptions back to the parent.\n",
        "\n",
        "#a. Using try-except Blocks in Each Process\n",
        "#Just like in threads, the simplest approach to handle exceptions is to use try-except blocks inside the target function of each process.\n",
        "#code\n",
        "from multiprocessing import Process\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        raise ValueError(\"Error in process\")\n",
        "    except Exception as e:\n",
        "        print(f\"Exception caught in process: {e}\")\n",
        "\n",
        "p = Process(target=task)\n",
        "p.start()\n",
        "p.join()\n",
        "#b. Using a Process Pool (multiprocessing.Pool)\n",
        "#When using a process pool (via multiprocessing.Pool), exceptions can be caught and handled using the apply, map, or apply_async methods. The pool workers capture the exceptions and propagate them back to the main process.\n",
        "#python\n",
        "#code\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def task(x):\n",
        "    if x == 5:\n",
        "        raise ValueError(\"Error in process\")\n",
        "    return x * x\n",
        "\n",
        "with Pool(4) as pool:\n",
        "    try:\n",
        "        results = pool.map(task, [1, 2, 3, 4, 5])\n",
        "        print(results)\n",
        "    except Exception as e:\n",
        "        print(f\"Exception caught: {e}\")\n",
        "#c. Using concurrent.futures.ProcessPoolExecutor\n",
        "#Like ThreadPoolExecutor, ProcessPoolExecutor from the concurrent.futures module provides an easy way to handle exceptions raised in processes. You can catch exceptions using the result() method of Future objects.\n",
        "#python\n",
        "#code\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "def task():\n",
        "    raise ValueError(\"An error occurred in the process\")\n",
        "\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    future = executor.submit(task)\n",
        "    try:\n",
        "        future.result()  # This will raise the exception if it occurred in the process\n",
        "    except Exception as e:\n",
        "        print(f\"Exception caught: {e}\")\n",
        "#d. Sharing Exceptions via Queues or Pipes\n",
        "#When you need more control, you can pass exceptions from child processes to the parent process using communication channels like queues or pipes.\n",
        "#python\n",
        "#code\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def task(queue):\n",
        "    try:\n",
        "        raise ValueError(\"Error in process\")\n",
        "    except Exception as e:\n",
        "        queue.put(e)\n",
        "\n",
        "queue = Queue()\n",
        "p = Process(target=task, args=(queue,))\n",
        "p.start()\n",
        "p.join()\n",
        "\n",
        "exception = queue.get()  # Retrieve the exception from the child process\n",
        "print(f\"Exception caught: {exception}\")\n",
        "#Best Practices for Handling Exceptions in Concurrent Programs\n",
        "#Always Use try-except Blocks:\n",
        "\n",
        "#Wrap critical sections of your code in try-except blocks to ensure that exceptions are caught and handled.\n",
        "#Propagate Exceptions to the Main Thread/Process:\n",
        "\n",
        "#Use thread or process management tools like concurrent.futures or custom exception handling in Thread/Process classes to ensure exceptions are propagated and handled centrally.\n",
        "#Log Exceptions:\n",
        "\n",
        "#Logging exceptions in concurrent environments helps identify issues without requiring immediate debugging. Use the logging module to capture and report exceptions.\n",
        "#python\n",
        "#code\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "try:\n",
        "    # Your code\n",
        "    pass\n",
        "except Exception as e:\n",
        "    logging.error(f\"Exception occurred: {e}\")\n",
        "#Use Graceful Shutdown:\n",
        "\n",
        "#Ensure that exceptions are handled in such a way that threads or processes can exit gracefully, releasing resources like locks, file handles, or network connections properly.\n",
        "#Test Concurrent Code Thoroughly:\n",
        "\n",
        "#Concurrent code can behave unpredictably due to the nature of thread/process scheduling. Use extensive testing to catch edge cases, especially those involving exceptions.\n",
        "#Conclusion\n",
        "#Handling exceptions in concurrent programs is critical for preventing program crashes, ensuring resource safety, avoiding deadlocks, and maintaining overall robustness. Python provides a range of techniques, from simple try-except blocks to advanced tools like ThreadPoolExecutor and ProcessPoolExecutor, to handle exceptions in both threads and processes. Proper exception management is essential for building resilient and efficient concurrent programs."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAXAzEiVIVSm",
        "outputId": "20fbe87d-3997-4f11-c16b-17fcedcccee0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception caught in thread: An error occurred in the thread\n",
            "Exception caught in main thread: Error in thread\n",
            "Exception caught: An error occurred in the thread\n",
            "Exception caught in process: Error in process\n",
            "Exception caught: Error in process\n",
            "Exception caught: An error occurred in the process\n",
            "Exception caught: Error in process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.Use concurrent.futures.ThreadPoolExecutor to manage the threads"
      ],
      "metadata": {
        "id": "XthUglSqJvlD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here’s an example Python program that uses a thread pool (concurrent.futures.ThreadPoolExecutor) to calculate the factorial of numbers from 1 to 10 concurrently:\n",
        "\n",
        "#python\n",
        "#code\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main code\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Using ThreadPoolExecutor to calculate factorials concurrently\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        # Map each number to the factorial function\n",
        "        results = executor.map(factorial, numbers)\n",
        "\n",
        "    # Printing results\n",
        "    for num, result in zip(numbers, results):\n",
        "        print(f\"Factorial of {num} is {result}\")\n",
        "#Explanation:\n",
        "#factorial(n) function: This function computes the factorial of a number using Python’s math.factorial() method and prints a message to indicate that the calculation is in progress.\n",
        "#ThreadPoolExecutor: We create a thread pool using ThreadPoolExecutor(), which automatically manages the threads.\n",
        "#executor.map(): The map() method assigns the factorial function to each number in the numbers range (1 to 10) and computes them concurrently.\n",
        "#Printing results: After the computations are done, we iterate over the results and print the factorial of each number.\n",
        "#Output Example:\n",
        "#plaintext\n",
        "#code\n",
        "#Calculating factorial of 1\n",
        "#Calculating factorial of 2\n",
        "#Calculating factorial of 3\n",
        "#Calculating factorial of 4\n",
        "#Calculating factorial of 5\n",
        "#Calculating factorial of 6\n",
        "#Calculating factorial of 7\n",
        "#Calculating factorial of 8\n",
        "#Calculating factorial of 9\n",
        "#Calculating factorial of 10\n",
        "#Factorial of 1 is 1\n",
        "#Factorial of 2 is 2\n",
        "#Factorial of 3 is 6\n",
        "#Factorial of 4 is 24\n",
        "#Factorial of 5 is 120\n",
        "#Factorial of 6 is 720\n",
        "#Factorial of 7 is 5040\n",
        "#Factorial of 8 is 40320\n",
        "#Factorial of 9 is 362880\n",
        "#Factorial of 10 is 3628800\n",
        "#This program efficiently calculates the factorial of multiple numbers concurrently using a thread pool, making the computation faster in multi-core systems."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ5qq1UdJ2bJ",
        "outputId": "51ce81af-1aea-40b2-c405-f6e6c24ef409"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating factorial of 1\n",
            "Calculating factorial of 2\n",
            "Calculating factorial of 3\n",
            "Calculating factorial of 4\n",
            "Calculating factorial of 5\n",
            "Calculating factorial of 6\n",
            "Calculating factorial of 7\n",
            "Calculating factorial of 8\n",
            "Calculating factorial of 9\n",
            "Calculating factorial of 10\n",
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "#processes)."
      ],
      "metadata": {
        "id": "AwAtUDqVKVrR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here’s a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. It measures the time taken for different pool sizes (e.g., 2, 4, 8 processes).\n",
        "\n",
        "#python\n",
        "#code\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to calculate square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure the computation time for a given pool size\n",
        "def compute_squares(pool_size):\n",
        "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
        "\n",
        "    # Create a pool of workers\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        start_time = time.time()  # Start the timer\n",
        "\n",
        "        # Compute the square of numbers in parallel\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "        end_time = time.time()  # End the timer\n",
        "\n",
        "    # Return the results and the time taken\n",
        "    return results, end_time - start_time\n",
        "\n",
        "# Main code\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [2, 4, 8]  # Different pool sizes to test\n",
        "\n",
        "    for size in pool_sizes:\n",
        "        results, time_taken = compute_squares(size)\n",
        "        print(f\"Pool size: {size}\")\n",
        "        print(f\"Results: {results}\")\n",
        "        print(f\"Time taken: {time_taken:.4f} seconds\\n\")\n",
        "#Explanation:\n",
        "#square(n) function: This function computes the square of a number.\n",
        "#compute_squares(pool_size) function: It creates a pool of workers with the specified size, computes the square of numbers from 1 to 10 using pool.map(), and measures the time taken for the computation.\n",
        "#pool.map(): This method distributes the workload across the pool of workers, allowing the computation to be performed in parallel.\n",
        "#Time measurement: The program records the time at the start and end of the computation and calculates the difference to determine the total time taken.\n",
        "#Testing different pool sizes: The program runs the computation with pool sizes of 2, 4, and 8 processes, and prints the results and time taken for each pool size.\n",
        "#Example Output:\n",
        "#plaintext\n",
        "#code\n",
        "#ool size: 2\n",
        "#Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "#Time taken: 0.1605 seconds\n",
        "\n",
        "#Pool size: 4\n",
        "#Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "#Time taken: 0.1198 seconds\n",
        "\n",
        "#Pool size: 8\n",
        "#Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
        "#Time taken: 0.0983 seconds\n",
        "#How the Program Works:\n",
        "#Parallel Execution: The program uses multiple processes to compute the squares of numbers in parallel. With more processes, the work is distributed across more CPU cores.\n",
        "#Time Measurement: By comparing the time taken with different pool sizes, you can see how increasing the number of processes can reduce computation time.\n",
        "#This program demonstrates the performance benefits of parallelism using multiprocessing.Pool and how to evaluate it with different pool sizes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ_REIJWKqOT",
        "outputId": "8df8a600-465d-4a95-8865-8c99fab1f373"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0103 seconds\n",
            "\n",
            "Pool size: 4\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0141 seconds\n",
            "\n",
            "Pool size: 8\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0129 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zbVQm0TLSIe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}